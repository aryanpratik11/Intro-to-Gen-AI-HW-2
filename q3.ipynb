{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Q3.Build an RNN to generate text character-by-character using PyTorch.\n",
    " - Convert text into one-hot vectors or embeddings.\n",
    " - Handle sequential dependencies with hidden states.\n",
    " - Train with Teacher Forcing vs. Free Running modes.\n",
    " - Implement sampling strategies like greedy search and temperature-based sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Generative AI transforms the way we create and innovate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_chars = sorted(list(set(text)))\n",
    "char_to_index = {char: i for i, char in enumerate(unique_chars)}\n",
    "index_to_char = {i: char for char, i in char_to_index.items()}\n",
    "vocab_size = len(unique_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_tensor(text):\n",
    "    return torch.tensor([char_to_index[char] for char in text], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tensor = text_to_tensor(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 16\n",
    "hidden_size = 128\n",
    "num_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights():\n",
    "    embedding_weights = torch.randn(vocab_size, embedding_size, requires_grad=True)\n",
    "    rnn_weights = torch.randn(embedding_size, hidden_size, requires_grad=True)\n",
    "    rnn_hidden_weights = torch.randn(hidden_size, hidden_size, requires_grad=True)\n",
    "    output_weights = torch.randn(hidden_size, vocab_size, requires_grad=True)\n",
    "    return embedding_weights, rnn_weights, rnn_hidden_weights, output_weights\n",
    "\n",
    "embedding_weights, rnn_weights, rnn_hidden_weights, output_weights = init_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(input_char, hidden):\n",
    "    embed = embedding_weights[input_char]\n",
    "    hidden = torch.tanh(torch.matmul(embed, rnn_weights) + torch.matmul(hidden.detach(), rnn_hidden_weights))\n",
    "    output = torch.matmul(hidden, output_weights)\n",
    "    return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(text_tensor, epochs=100, learning_rate=0.01, teacher_forcing_ratio=0.5):\n",
    "    optimizer = optim.Adam([embedding_weights, rnn_weights, rnn_hidden_weights, output_weights], lr=learning_rate)\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        hidden = torch.zeros(hidden_size)\n",
    "        total_loss = 0\n",
    "        \n",
    "        for i in range(len(text_tensor) - 1):\n",
    "            input_char = text_tensor[i]\n",
    "            target_char = text_tensor[i + 1].unsqueeze(0)\n",
    "            \n",
    "            output, hidden = forward_pass(input_char, hidden)\n",
    "            \n",
    "            loss = loss_function(output.unsqueeze(0), target_char)\n",
    "            total_loss += loss.item()  # Use .item() to detach from computation graph\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}: Loss = {total_loss:.4f}\")  # Avoid calling .item() on total_loss directly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 1122.4318\n",
      "Epoch 10: Loss = 319.1014\n",
      "Epoch 20: Loss = 148.3770\n",
      "Epoch 30: Loss = 75.3114\n",
      "Epoch 40: Loss = 22.6483\n",
      "Epoch 50: Loss = 38.0736\n",
      "Epoch 60: Loss = 69.5783\n",
      "Epoch 70: Loss = 13.5266\n",
      "Epoch 80: Loss = 44.8423\n",
      "Epoch 90: Loss = 35.3693\n",
      "Epoch 100: Loss = 35.3084\n",
      "Epoch 110: Loss = 7.0400\n",
      "Epoch 120: Loss = 2.7832\n",
      "Epoch 130: Loss = 69.4346\n",
      "Epoch 140: Loss = 19.8190\n",
      "Epoch 150: Loss = 14.5419\n",
      "Epoch 160: Loss = 16.5938\n",
      "Epoch 170: Loss = 35.7077\n",
      "Epoch 180: Loss = 44.1293\n",
      "Epoch 190: Loss = 0.1838\n"
     ]
    }
   ],
   "source": [
    "train(text_tensor, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(start_text, length=100, temperature=1.0):\n",
    "    hidden = torch.zeros(hidden_size)\n",
    "    input_sequence = text_to_tensor(start_text)\n",
    "    output_text = start_text\n",
    "    \n",
    "    for _ in range(length):\n",
    "        output, hidden = forward_pass(input_sequence[-1], hidden)\n",
    "        output = output / temperature\n",
    "        probabilities = F.softmax(output, dim=-1).detach().numpy()\n",
    "        next_char_index = np.random.choice(range(vocab_size), p=probabilities.ravel())\n",
    "        output_text += index_to_char[next_char_index]\n",
    "        input_sequence = torch.cat((input_sequence, torch.tensor([next_char_index])), dim=0)\n",
    "    \n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative Aate AI te create AI nnd innovatewe Aate cre way we create AI AI rate cre way we cre way way we cre\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(\"Generative\", length=100, temperature=0.8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
